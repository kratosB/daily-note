1. [redis为什么这么快](https://mp.weixin.qq.com/s?__biz=MzkzMDI1NjcyOQ==&mid=2247487752&idx=1&sn=72a1725e1c86bb5e883dd8444e5bd6c4&chksm=c27c533ef50bda288417c31f5210bb16a70361b2e2c344dfffdb079b54b241cd6c62202d9775&scene=178&cur_album_id=1918295695426404359#rd `Redis 核心篇：唯快不破的秘密`)
   1. 全部基于内存
   2. -----redis整体就是一个哈希表
      1. 底层是一个数组，里面的元素是哈希桶，桶里是链表，链表里存指针。
      2. 用了两个全局哈希表，用于rehash。
      3. 采用渐进式hash，避免阻塞。
   3. 合理的数据结构
      1. 例如String，如果是数字，就用数字，如果是字符串，就用sds。
      2. sds的特点
         1. 专门字符记录字符串的length，可以直接返回（O(1)复杂度）
         2. 空间预分配，不用每次重新分配
         3. 惰性释放空间，字符串变短之后，不回收空域部分，留着以后（可能会）再用，省得下次重新分配
         4. -----二进制安全，因为c语言中字符串用'\0'做结尾
      3. -----ziplist
         1. list，hash和zSet，都会用到这种数据结构
         2. 底层是连续内存块组成的，挨个紧凑存储的列表
         3. 有三个字段
            1. zlbytes：整个压缩列表占用字节数
            2. zltail_offset：最后一个的偏移量
            3. zllength：元素个数
         4. 队尾有一个zlend（恒定为0xFF），表示列表结束
         5. 数量小的时候，可以找头尾，也可以直接返回大小，速度快
      4. 跳跃表
         1. 链表+多级索引，查询速度变快
      5. 总的来说，很多都是空间换时间的例子。
   4. -----合理的数据编码
      1. redis使用对象来存储数据（key和value都是）
      2. 对于一种数据（例如String或者Hash），底层有多种数据结构，根据编码来转化。
      3. String
         1. 数字的话，是int类型编码
         2. 非数字，是raw编码
      4. List
         1. 长度<64字节 + 元素数<512，用ziplist
         2. 反之，用linkedlist
         3. 新版升级成quicklist了（整体是linkedlist，linkedlist被分成很多个小段，每一段都是ziplist）
      5. Hash
         1. 键值对的键和值长度<64字节 + 键值对数量<512，用ziplist
         2. 反之，用hashtable
      6. Set
         1. 保存数据是整数，且元素数量小，用intset
            1. 有序数组+length
         2. 反之，用hashtable
      7. Zset
         1. 元素个数<128 + 元素成员长度<64字节，用ziplist
            1. 用ziplist的时候，键值对连续存储，例如（zlbytes|zltail|zllen|java|5.0|python|6.0|html|7.0|zlend）
         2. 反之，用zkiplist
   5. 合理的线程模型
      1. -----redis的单线程，是指，redis的网络IO，以及键值对读写，是由一个线程来执行的。
      2. 多路复用
         1. -----redis使用epoll技术 + 事件框架实现多路复用。
         2. -----redis事件处理模型将epoll中的连接，读写，关闭都转化为事件。
         3. （个人理解）简单说就是把多个请求做成很多个事件，然后轮询处理事件。
      3. 单线程
         1. 处理内存部分是单线程，后台操作等部分（持久化，集群，异步删除）是多线程
         2. 因为cpu不是瓶颈，内存速度才是瓶颈
         3. 多线程麻烦多，例如切换上下文，锁竞争，等等。
         4. -----缺点是大key会阻塞。
   6. -----虚拟内存机制
      1. 冷数据交换到磁盘
      2. 内存留给热数据
2. redis和mysql一致性
   1. 为什么要删除，不要更新：
      1. 因为更新了不一定会被用上，导致浪费
      2. -----并发更新容易出现脏数据
      3. -----删除会有一次cache miss（大多数情况可以接受）
      4. -----可以根据读多写少/读少写多/热key等特点。决定用哪种方式
   2. 先删缓存再更新数据库
      1. 问题：更新数据库之前，有查请求，又把旧的数据写到缓存里面了，导致不一致。
      2. 解决：延迟双删
      3. 新的问题：延迟双删第二次失败了，导致不一致。
   3. 先更新数据库再删缓存
      1. 问题：
         1. 更新完删缓存失败
         2. 有一点延迟
      2. 解决：
         1. 队列帮忙删缓存
            1. 缺点：延迟没解决，引入队列增加复杂度
         2. 监视binlog来删除缓存
            1. 缺点：延迟没解决，但是延迟就跟mysql的主从一样，可以接受
   4. 普通数据一定要设置超时时间，可以保证最终一致性。（以免下次请求来才修复错误缓存的问题）
3. redis缓存击穿/缓存穿透/缓存雪崩
   1. 击穿
      1. 描述：热key过期之后，许多请求都直接打到mysql，数据库崩溃
      2. 解决：
         1. 热key不过期
         2. 单机用java锁，分布式用分布式锁。
   2. 穿透
      1. 描述：请求的值mysql中没有，所以每次都会直接访问mysql
      2. 原因
         1. -----业务设计不合理
         2. 非法攻击
         3. -----数据误删
      3. 解决
         1. 空标记
         2. 布隆过滤器
         3. -----api层面拦截非法攻击
   3. 雪崩
      1. 描述：很多缓存同时失效，请求全部打到mysql，数据库崩溃
      2. 解决：
         1. 设置不同的过期时间
         2. 热点数据不过期
         3. 集群
4. redis持久化
   1. RDB
      1. 快照
         1. 优点
            1. 创建/恢复速度块
            2. -----快照适合大规模备份恢复
            3. -----快照只记录最后状态，例如已过期数据不在RDB中。
         2. 缺点
            1. -----没法实施持久化
            2. -----生成频率不好把握
      2. save
         1. 主动调用，主线程执行，会阻塞
      3. bgsave
         1. 每隔一段时间/每隔xx次操作，-----调用glibc函数，fork出一个线程写RDB，不阻塞。
         2. fork的时候会阻塞，所以如果redis数据量太大，会影响性能
         3. 用了类似COW的技术，才能实现持久化+写同时进行，不然只能持久化+读。
            1. -----主线程写原本，子线程用副本。
   2. AOF
      1. -----追加写文件的形式，记录每一个操作。先写redis，再写日志（所以叫写后日志）
         1. 优点：
            1. 数据全（-----一致性完整性高）
            2. -----写后日志确保数据正确性，避免语法检查开销。
         2. 缺点：
            1. 文件大（因为同一个key，可能会写上好多次，而且有些key可能已经删了，但是还要操作一次）
            2. 恢复速度慢（原因同上）
      2. 记录频率可选
         1. 每条都记（-----appendfsync = always：同步写回，性能低，可靠性好。）
         2. 每秒都记（-----appendfsync = everysec：每秒写回，性能可靠性折中。）
         3. 自动（-----appendfsync = no：系统自己决定时间写磁盘，性能高，可靠性低。）
      3. -----AOF重写机制（可以精简AOF）
         1. 用一个子进程对内存进行遍历，转化成redis指令
         2. 把指令写到新的AOF文件中
         3. 然后把期间的操作产生的增量AOF追加到这个新的AOF文件中
         4. 用新的AOF替换旧的AOF
   3. RDB+AOF（-----redis4.0混合日志模型）
      1. 每隔一段时间，用RDB记录，两次RDB中间的部分，用AOF记录
      2. -----RDB的运行频率可以稍微慢一点
      3. -----恢复的时候先恢复RDB，再恢复AOF
5. redis主从
   1. -----为什么需要主从
      1. 故障恢复
      2. 负载均衡
      3. 高可用基础
   2. 一主多从，读写分离
      1. 主负责写，从负责读
      2. 优点：
         1. 分散压力
         2. 有从库备份
      3. 缺点：
         1. 需要手动切换（-----手动切换主从，应用放也得切换）
   3. 用RDB实现
      1. 因为RDB传输快，写磁盘快
      2. RDB恢复快
   4. 三种情况
      1. 同步刚开始（-----全量同步）
         1. slave请求同步
         2. master执行bgsave生成RDB，发送RDB
         3. master给每个slave搞一块区域（-----replication buffer），  
         用来存储（-----bgsave开始的所有写命令）期间产生的新RDB数据
         4. slave加载完RDB之后，master再发送replication buffer中的数据
      2. 连接正常
         1. 增量复制
            1. redis开辟了一块repl_backlog_buffer，专门用来记录同步数据。
            2. buffer是一个环形的数据结构（类似redo log），master管理自己的master_repl_offset，  
            每个slave维护自己的slave_repl_offset。
            3. 每次slave来请求（包括断开重连），发送slave_repl_offset，  
            master会返回master_repl_offset-slave_repl_offset之间的数据。
            4. 如果slave_repl_offset被写master_repl_offset套圈，那么就算作同步失败，要重新全量同步。  
            -----所以repl_backlog_buffer要稍微大一点。
         2. -----主从之间维持心跳
            1. 主从 PING：主用来判断超时的
            2. 从主 REPLCONF ACK：
               1. 默认每秒一次
               2. 会带上replication_offset
               3. 检测网络状态，并获取同步数据
      3. 断连
         1. 2.8之前，断了直接全量复制。2.8之后，断了采用增量复制。
         2. 增量复制上面正常连接部分说了。
6. redis哨兵
   1. 为什么需要哨兵
      1. 因为哨兵可以在master挂掉的时候自动切换主备。
   2. 一主多从，主从读写分离，奇数个哨兵。
      1. 哨兵监控主从工作状态。
      2. master挂了，哨兵选举切换新的master
      3. 通知其他slave更换master
   3. 哨兵监视的过程
      1. -----哨兵之间，哨兵和master/slave之间，保持一个心跳。
      2. 主观下线：哨兵发现master没心跳了，标记成主观下线（可能是自己的网络有问题）
      3. 客观下线：超过一半哨兵标记master主观下线，标记成客观下线，开始选举
   4. 自动切换主库
      1. 选的时候，参考的维度很多
         1. -----没下线的slave
         2. 网络状况最好的（最少断之类的）
         3. 打分
            1. -----可以手动设置优先级
            2. 谁跟主最接近（-----slave_repl_offset最新的）
            3. -----slave的runID（正常运行时间最久的，最可靠）
   5. -----哨兵工作原理。
      1. 哨兵只配置了监控master ip/port
      2. master有一个哨兵专用通道，哨兵通过pub/sub机制互相获取信息。
      3. 哨兵向master发送info，master返回slave列表。
      4. 哨兵通过pub/sub通知客户端（客户端需要订阅哨兵消息）。
7. redis集群
   1. 为什么需要集群
      1. 数据量大（千万级别）了查询慢
      2. 数据量大了RDB fork慢，会阻塞
   2. 集群的实现
      1. 集群被划分为16384个hash slot，每个redis实例负责一部分slot
      2. -----对传入key，使用CRC16算法，计算出一个16bit的值
      3. 16bit的值对16384取模，得到对应slot
      4. 根据slot找到redis实例
   3. Hash Slot与redis实例
      1. 所有（16384）哈希槽分配完，集群就启动了，不然不会工作
      2. -----可以自动分配slot，也可以手动分配slot
   4. 集群里有人挂了怎么办
      1. 给master安排slave，集群里的slave只负责备份，不负责读写分离
      2. master挂了会自动选举新的slave来管理这些哈希槽。
      3. 如果没有slave，master挂了，集群就不可用了，可以设置**cluster-require-full-coverage参数**为可用。
      4. -----大大多数master发现一个master失联了，集群就认为它下线了，需要主从切换。新master会广播信息。
   5. 如何查询（-----客户端如何定位数据）
      1. -----redis实例会将slot信息通过gossip协议发给其他实例，集群中每个实例都有所有的slot-实例信息。
      2. 客户端对key做CRC16计算，取模，算出对应的slot信息。
      3. 查任意一个实例，实例就会把所有实例（ip+port）和哈希槽的映射发给客户端，客户端存在本地
      4. 客户端去找对应的实例拿数据
   6. 能不能用一个表存所有的key，这样就不用hash槽了。
      1. 不能，这样本质上没有分散压力，这个表压力容易过大（单线程性能差，多线程加锁复杂）
      2. 存这么多key也需要很多空间
      3. hash效率高
      4. -----键值对和实例关系改变（例如重新分片，实例增减），需要修改表
   7. 查的时候数据正在迁移怎麽办（hash slot与redis实例对应关系改变。）
      1. -----集群中通过Gossip协议互相传递/更新slot分配消息。
      2. 数据完全迁移了：
         1. 实例返回一个moved + 新的ip:port
         2. 客户端更新本地哈希槽映射数据
         3. 客户端到新的ip:port找数据
      3. 数据迁移了一半：
         1. -----如果数据还在这个实例
            1. 直接返回对应的数据
         2. 如果数据已经迁移
            1. 实例返回一个ask + 新的ip:port
            2. -----客户端给新的实例发送一个ASKING命令
            3. 客户端到新的ip:port找数据
   8. 集群的规模
      1. 官方说1000个
      2. 原因：心态太费连接资源了
      3. 心跳机制：
         1. 每秒一个心跳
         2. 每次抽查5个，然后找到5个里面最久没更新的那个，所有的人给他发一个心跳（PING）。
         3. -----每100ms扫描本地实例列表，发现太久（可以设定时间）没收到PONG消息的实例，所有实例给他发一个
            1. 这个时间不能太久，太久的话，-----会导致故障没有被及时发现。
            2. 这个时间不能太短，费资源。
8. redis分布式锁
   1. 单机用lock和sync，分布式环境用分布式锁
   2. 加锁
      1. 唯一性：要用唯一的id，一个key，然后用NX来确保唯一，已经存在的话就会加锁失败
      2. 防止被别人解锁：所以要设置一个随机的value
      3. 防止死锁：所以要设置超时时间
      4. 原子性：所以要一句话设置，例如set key value NX PX 30000
   3. 解锁
      1. 先判断这个锁是不是我的，用value，
      2. 然后解锁
      3. redis没有能满足这个要求的原子性操作，所以用lua
   4. 超时任务还没做完，redisson
   5. -----可重入，可以把value做成一个map（value：count）
   6. 最好加上一个回滚，如果出问题了，就回滚？这个是分布式锁还是分布式事务？
   7. [RedisTemplate实现分布式锁](https://www.jianshu.com/p/30d7212a2770/)
      1. 加锁的时候，2.xx之后版本的redisTemplate有setIfAbsent(key,value,time,unit)方法。
      2. 解锁的时候，需要一个lua的配置文件，redisTemplate去execute一下这个脚本（配置文件）。
9. 布隆
   1. 数据结构
      1. 好多个hash算法
      2. 一个很大很大的存bit的向量
   2. 使用
      1. 查询
         1. 每次查询的时候，把要查的key用这几个hash算法算一下，得到index1，2，3，4，。。。。。
         2. 去这几个位置看一下，bit是不是1，如果都是1，则这个数据有可能存在，如果有任意一个不是1，则肯定不存在。
      2. 新增
         1. 每次新增数据的时候，把key用hash算一下，得到index1，2，3，4.。。。。。。。
         2. 去找到对应的位置，把bit改成1
   3. 原理
      1. 如果这个东西存在，那么他的key经过hash计算之后，这几个index肯定是1。
      2. 所以如果这几个index任意一个不是1，那肯定不存在。
      3. 如果这几个index都是1，那说明有可能存在。为什么只是有可能呢，因为这个1，可能是其他数据hash出来的。
   4. 优点
      1. 空间使用很少
      2. hash计算速度快
      3. 时间/空间效率高
   5. 缺点
      1. 需要初始化
      2. 会误判（-----假阳性），数据多了误判更容易
      3. 不能删除
   6. 升级
      1. 布谷鸟
      2. 用count代替1，这样就可以删除了，但是数据量大大增加，而且感觉效果不一定好
10. redlock--------------------------------------------------------------------------------
    1. 实现
       1. 部署2n+1个redis实例。
       2. 客户端向所有实例请求加锁。
       3. 超过一半加锁成功，就看作加锁成功。
       4. 需要客户端和redis实例的时间戳，用来判断加锁时间，以及是否超时。（细节记不清了）
    2. 问题
       1. 加锁成功之后，GC了，然后超时了，GC结束，线程以为自己还有锁，继续工作
       2. 依赖时间戳
       3. 太复杂
11. redisson看门狗
    1. 功能
       1. -----防止业务还没做完（因为GC等原因），锁已经过期了
       2. 可重入
    2. 起一个守护线程，每隔一段时间监控主线程有没有结束/挂掉，如果还在运行，就给超时时间续命。
    3. -----redisson的可重入，其实就是把value做成一个map(value:count)
    4. -----底层也是lua
12. 为什么之前用单线程，后面用多线程
    1. 之前用了多路复用技术，性能已经很强了
    2. 现在请求量实在太大了，所以能优化的地方都要优化，能增强一点是一点。
-------------------------------------------------------------
13. 过期策略和内存淘汰策略
    1. 过期策略
       1. 定时过期
          1. 实现：每个key设置定时器监听，过期就删掉
          2. 优点：省内存
          3. 缺点：太耗cpu
       2. 惰性过期
          1. 实现：每次select到这个key，判断是不是过期，是的话就删除
          2. 优点：cpu友好
          3. 缺点：内存不友好，可能会造成好多key过期未删除
       3. 定期过期
          1. 实现：每隔一定时间，扫描一部分key，里面有过期的就删掉
          2. 优点：cpu内存都比较友好，折中方案
          3. 缺点：需要调整时间，找到最适合的策略
       4. 定期+惰性混合使用
    2. 内存淘汰策略
       1. 所有key，随机删除
       2. 所有key，lru删除
       3. 所有key，lfu删除
       4. 直接报错
       5. 设定过期时间的key，随机删除
       6. 设定过期时间的key，删除最老的
       7. 设定过期时间的key，lru删除
       8. 设定过期时间的key，lfu删除
14. 应用场景
15. redis跳跃表
16. 事务机制
17. -----hash冲突怎麽办
    1. 底层就是hash表+hash桶（桶内部是链表）
    2. 为了保持高效，redis会做rehash（增加hash桶，减少冲突）
    3. redis使用两个全局hash表，一个用于当前使用，一个用于扩容
       1. 给hash表2（备用表）分配更大空间
       2. 将hash表1的数据映射到hash表2
       3. 释放hash表1的空间
    4. hash表1 -> hash表2，采用渐进式rehash（简单说就是，分多次，一个个索引，逐个拷贝，防止阻塞）
18. RDB期间，redis可以处理写请求吗（这个上面好像说了，要用COW技术）
    1. save会阻塞
    2. bgsave的fork会阻塞
    3. bgsave的其他环节不回阻塞，但是只能读数据，不能写
    4. 用了COW之后，就可以同时读写
